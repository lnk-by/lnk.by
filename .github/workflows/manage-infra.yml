name: 🖧 Manage AWS Infrastructure

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment'
        required: true
        default: 'DEVELOPMENT'
        type: choice
        options:
          - DEVELOPMENT
          - STAGING
          - PRODUCTION
      region:
        description: 'AWS Region'
        required: true
        default: 'eu-north-1'
        type: choice
        options:
            - us-east-1
            - us-east-2
            - us-west-1
            - us-west-2
            - ca-central-1
            - eu-west-1
            - eu-west-2
            - eu-west-3
            - eu-central-1
            - eu-north-1
            - eu-south-1
            - ap-southeast-1
            - ap-southeast-2
            - ap-northeast-1
            - ap-northeast-2
            - ap-south-1
            - ap-east-1
            - ap-northeast-3
            - sa-east-1
            - af-south-1
            - me-south-1
            - me-central-1
            - il-central-1
            - cn-north-1
            - cn-northwest-1
      api_gateway:
        description: 'API Gateway name (leave empty if you do not want to manage it)'
        type: string
      user_pool:
        description: 'Manage Cognito User Pool (leave empty if you do not want to manage it)'
        type: string
      s3_bucket:
        description: 'S3 Bucket name (leave empty if you do not want to manage it)'
        type: string
      rds_data:
        description: 'RDS data (DBID, DB name, username, password), example: db-dev-1,postgres,postgres,mypassword'
        type: string
      manage_db:
        description: 'RDS instance'
        type: boolean
        default: false
      manage_schema:
        description: 'RDS Schema + Tables'
        type: boolean
        default: false
      operation:
        description: 'Deploy or Remove'
        required: true
        type: choice
        options:
          - 🚀 Deploy
          - 🗑️ Remove
          - 🔁 Remove & Deploy

run-name: >-
  🖧
  ${{ github.event.inputs.operation }}(${{ github.event.inputs.environment }}):
  ${{ github.event.inputs.api_gateway != '' && format('📡 {0}', github.event.inputs.api_gateway) || '' }}
  ${{ github.event.inputs.user_pool != '' && format('👤 {0}', github.event.inputs.user_pool) || '' }}
  ${{ github.event.inputs.s3_bucket != '' && format('🪣 {0}', github.event.inputs.s3_bucket) || '' }}
  ${{ github.event.inputs.manage_db == 'true' && '🐘' || '' }}
  ${{ github.event.inputs.manage_schema == 'true' && '🗂️' || '' }}
jobs:
  manage:
    name: '${{ github.event.inputs.operation }} Infra'
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment }}

    env:
      AWS_REGION: ${{ github.event.inputs.region }}
      BUCKET_NAME: ${{ github.event.inputs.s3_bucket }}
      USER_POOL_NAME: ${{ github.event.inputs.user_pool }}
      HTTP_API_NAME: ${{ github.event.inputs.api_gateway }}
      DB_SQL_CREATE: ./shared/db/create.sql
      DB_SQL_DROP: ./shared/db/drop.sql
      GH_TOKEN: ${{ secrets.GH_TOKEN }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Parse RDS Data
        id: parse_rds
        if: ${{ inputs.rds_data != '' }}
        run: |
            DB_DATA=$(echo "${{ inputs.rds_data }}" | sed 's/^ *//g' | sed 's/ *$//g' | sed 's/ *, */,/g')
            IFS=',' read -r DB_IDENTIFIER DB_NAME DB_USER DB_PASSWORD <<< "$DB_DATA"
            echo "DB_IDENTIFIER=$DB_IDENTIFIER" >> "$GITHUB_ENV"
            echo "DB_NAME=$DB_NAME" >> "$GITHUB_ENV"
            echo "DB_USER=$DB_USER" >> "$GITHUB_ENV"
            echo "DB_PASSWORD=$DB_PASSWORD" >> "$GITHUB_ENV"
            echo "inputs.manage_schema=${{ inputs.manage_schema }}"

      - name: Setup AWS CLI
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ github.event.inputs.region }}

      # Remove

      # API Gateway
      - name: Delete API Gateway
        if: ${{ inputs.api_gateway != '' && contains(inputs.operation, 'Remove') }}
        run: |
          id=$(aws apigatewayv2 get-apis --query "Items[?Name=='$HTTP_API_NAME'].ApiId" --output text)
          [[ -n "$id" ]] && aws apigatewayv2 delete-api --api-id "$id"
          for VAR in AWS_API_ID AWS_AUTHORIZER_ID; do
            gh variable get "$VAR" --env "${{ github.event.inputs.environment }}" && gh variable delete "$VAR" --env "${{ github.event.inputs.environment }}"
          done

      # Cognito
      - name: Delete User pool
        if: ${{ inputs.user_pool != '' && contains(inputs.operation, 'Remove') }}
        run: |
          id=$(aws cognito-idp list-user-pools --max-results 50 --query "UserPools[?Name=='$USER_POOL_NAME'].Id" --output text)
          [[ -n "$id" ]] && aws cognito-idp delete-user-pool --user-pool-id "$id"
          gh variable get AWS_USER_POOL_ID --env "${{ github.event.inputs.environment }}" && gh variable delete AWS_USER_POOL_ID --env "${{ github.event.inputs.environment }}"


      # S3 Bucket
      - name: Remove S3 bucket
        if: ${{ inputs.s3_bucket != '' && contains(inputs.operation, 'Remove') }}
        run: |
          aws s3 rm "s3://$BUCKET_NAME" --recursive || true
          aws s3api delete-bucket --bucket "$BUCKET_NAME"
          gh variable get S3_BUCKET --env "${{ github.event.inputs.environment }}" && gh variable delete S3_BUCKET --env "${{ github.event.inputs.environment }}"

      # PostgreSQL schema
      - name: Drop DB Schema
        if: ${{ inputs.manage_schema == true && contains(inputs.operation, 'Remove') }}
        run: |
          endpoint=$(aws rds describe-db-instances \
            --db-instance-identifier "$DB_IDENTIFIER" \
            --query 'DBInstances[0].Endpoint.Address' \
            --output text)

          PGPASSWORD=$DB_PASSWORD psql -h "$endpoint" -U "$DB_USER" -d "$DB_NAME" -f "$DB_SQL_DROP"

      # RDS PostgreSQL
      - name: Drop RDS instance
        if: ${{ inputs.manage_db == true && contains(inputs.operation, 'Remove') }}
        run: |
          aws rds delete-db-instance --db-instance-identifier "$DB_IDENTIFIER" --skip-final-snapshot
          for VAR in DB_URL JDBC_URL DB_USER; do
            gh variable get "$VAR" --env "${{ github.event.inputs.environment }}" && gh variable delete "$VAR" --env "${{ github.event.inputs.environment }}"
          done
          gh secret set DB_PASSWORD --env "${{ github.event.inputs.environment }}" --body "$DB_PASSWORD"

      # Deploy

      - name: Save general parameters for deployment
        if: ${{ contains(inputs.operation, 'Deploy') }}
        run: |
          gh variable set AWS_REGION --env "${{ github.event.inputs.environment }}" --body "$AWS_REGION"


      # Cognito
      - name: Create User pool
        if: ${{ inputs.user_pool != '' && contains(inputs.operation, 'Deploy') }}
        run: |
          USER_POOL_JSON=$(aws cognito-idp create-user-pool --pool-name "$USER_POOL_NAME")
          USER_POOL_ID=$(echo "$USER_POOL_JSON" | grep '"Id":' | cut -d '"' -f4)

          USER_POOL_CLIENT_ID=$(aws cognito-idp create-user-pool-client \
          --user-pool-id "$USER_POOL_ID" \
          --client-name 'my-app-client' \
          --no-generate-secret \
          --explicit-auth-flows ALLOW_USER_PASSWORD_AUTH ALLOW_REFRESH_TOKEN_AUTH ALLOW_USER_SRP_AUTH \
          --query 'UserPoolClient.ClientId' \
          --output text)

          echo "Created User Pool with ID $USER_POOL_ID"
          echo "Created User Pool Client with ID $USER_POOL_CLIENT_ID"
          gh variable set AWS_APP_CLIENT_ID --env "${{ github.event.inputs.environment }}" --body "$USER_POOL_CLIENT_ID"
          gh variable set AWS_USER_POOL_ID --env "${{ github.event.inputs.environment }}" --body "$USER_POOL_ID"

      # API Gateway
      - name: Create API Gateway
        if: ${{ inputs.api_gateway != '' && contains(inputs.operation, 'Deploy') }}
        run: |
            USER_POOL_ID=$(aws cognito-idp list-user-pools --max-results 50 --query "UserPools[?Name=='$USER_POOL_NAME'].Id" --output text)
            APP_CLIENT_ID=$(aws cognito-idp list-user-pool-clients --user-pool-id "$USER_POOL_ID" --query 'UserPoolClients[0].ClientId' --output text)

            API_ID=$(aws apigatewayv2 create-api --name "$HTTP_API_NAME" --protocol-type HTTP --query 'ApiId' --output text)

            AUTHORIZER_ID=$(aws apigatewayv2 create-authorizer \
            --api-id "$API_ID" \
            --authorizer-type JWT \
            --name CognitoAuthorizer \
            --identity-source '$request.header.Authorization' \
            --jwt-configuration "Issuer=https://cognito-idp.${AWS_REGION}.amazonaws.com/${USER_POOL_ID},Audience=${APP_CLIENT_ID}" \
            --query 'AuthorizerId' \
            --output text)

            aws apigatewayv2 create-stage --api-id "$API_ID" --stage-name '$default' --auto-deploy

            echo "Created API gateway with ID $API_ID"
            echo "Created Authorizer with ID $AUTHORIZER_ID"
            gh variable set AWS_API_ID --env "${{ github.event.inputs.environment }}" --body "$API_ID"
            gh variable set AWS_AUTHORIZER_ID --env "${{ github.event.inputs.environment }}" --body "$AUTHORIZER_ID"


      - name: Ensure S3 VPC Endpoint exists
        if: ${{ inputs.s3_bucket != '' && contains(inputs.operation, 'Deploy') }}
        run: |
          - name: Ensure S3 VPC Endpoint exists
            run: |
              set -euo pipefail

              SERVICE="com.amazonaws.${AWS_REGION}.s3"

              echo "🔍 Looking for default VPC in region $AWS_REGION..."
              VPC_ID=$(aws ec2 describe-vpcs --filters Name=isDefault,Values=true --query "Vpcs[0].VpcId" --output text)

              if [[ "$VPC_ID" == "None" || -z "$VPC_ID" ]]; then
                echo "❌ No default VPC found in $AWS_REGION" >&2
                exit 1
              fi

              echo "Default VPC ID: $VPC_ID"

              echo "🔎 Checking for existing S3 VPC endpoint in VPC $VPC_ID..."
              ENDPOINT_ID=$(aws ec2 describe-vpc-endpoints \
                --filters Name=vpc-id,Values="$VPC_ID" Name=service-name,Values="$SERVICE" \
                --query "VpcEndpoints[0].VpcEndpointId" \
                --output text)

              if [[ "$ENDPOINT_ID" != "None" && -n "$ENDPOINT_ID" ]]; then
                echo "✅ S3 VPC Endpoint already exists: $ENDPOINT_ID"
                exit 0
              fi

              echo "No S3 VPC endpoint found. Retrieving route tables for VPC $VPC_ID..."
              ROUTE_TABLES=$(aws ec2 describe-route-tables --filters Name=vpc-id,Values="$VPC_ID" --query "RouteTables[].RouteTableId" --output text)

              if [[ -z "$ROUTE_TABLES" ]]; then
                echo "❌ No route tables found for VPC $VPC_ID" >&2
                exit 1
              fi

              echo "➕ Creating S3 VPC endpoint for VPC $VPC_ID..."
              aws ec2 create-vpc-endpoint --vpc-id "$VPC_ID" --service-name "$SERVICE" --route-table-ids $ROUTE_TABLES --vpc-endpoint-type Gateway

              echo "✅ S3 VPC Endpoint created successfully."


      # S3 Bucket
      - name: Create S3 bucket
        if: ${{ inputs.s3_bucket != '' && contains(inputs.operation, 'Deploy') }}
        run: |
          aws s3api create-bucket --bucket "$BUCKET_NAME" --region "$AWS_REGION" --create-bucket-configuration LocationConstraint="$AWS_REGION"
          echo "Waiting for bucket $BUCKET_NAME to be ready..."
          aws s3api wait bucket-exists --bucket "$BUCKET_NAME"

          # Disable block public access
          aws s3api put-public-access-block \
            --bucket "$BUCKET_NAME" \
            --public-access-block-configuration BlockPublicAcls=false,IgnorePublicAcls=false,BlockPublicPolicy=false,RestrictPublicBuckets=false

          # Add bucket policy for public read
          aws s3api put-bucket-policy \
            --bucket "$BUCKET_NAME" \
            --policy '{
              "Version": "2012-10-17",
              "Statement": [
                {
                  "Sid": "AllowPublicReadAndList",
                  "Effect": "Allow",
                  "Principal": "*",
                  "Action": [
                    "s3:ListBucket",
                    "s3:GetObject"
                  ],
                  "Resource": [
                    "arn:aws:s3:::'"$BUCKET_NAME"'",
                    "arn:aws:s3:::'"$BUCKET_NAME"'/*"
                  ]
                },
                {
                  "Sid": "AllowPublicWriteToLandingPagesConf",
                  "Effect": "Allow",
                  "Action": [
                    "s3:GetObject",
                    "s3:PutObject"
                  ],
                  "Resource": "arn:aws:s3:::'"$BUCKET_NAME"'/landingpages/conf/*"
                }
              ]
            }'
          gh variable set S3_BUCKET --env "${{ github.event.inputs.environment }}" --body "$BUCKET_NAME"


      # RDS PostgreSQL
      - name: Deploy RDS instance
        if: ${{ inputs.manage_db == true && contains(inputs.operation, 'Deploy') }}
        run: |
            aws rds create-db-instance \
              --db-instance-identifier "$DB_IDENTIFIER" \
              --db-instance-class db.t3.micro \
              --engine postgres \
              --master-username "$DB_USER" \
              --master-user-password "$DB_PASSWORD" \
              --allocated-storage 20

            echo "Waiting for DB instance '$DB_IDENTIFIER' to become available..."
            aws rds wait db-instance-available --db-instance-identifier "$DB_IDENTIFIER"
            echo "DB is now available."

            endpoint=$(aws rds describe-db-instances \
                --db-instance-identifier "$DB_IDENTIFIER" \
                --query 'DBInstances[0].Endpoint.Address' \
                --output text)

            db_url="postgresql://$endpoint:5432/${DB_NAME}"
            jdbc_url="jdbc:postgresql://$endpoint:5432/${DB_NAME}?sslmode=require"
            echo "DB with requested USER and PASSWORD is created and can be acccessed via DB URL $db_url or JDBC URL $jdbc_url"
            gh variable set DB_URL --env "${{ github.event.inputs.environment }}" --body "$db_url"
            gh variable set JDBC_URL --env "${{ github.event.inputs.environment }}" --body "$jdbc_url"
            gh variable set DB_USER --env "${{ github.event.inputs.environment }}" --body "$DB_USER"
            gh secret set DB_PASSWORD --env "${{ github.event.inputs.environment }}" --body "$DB_PASSWORD"


      # PostgreSQL schema
      - name: Deploy DB Schema
        if: ${{ inputs.manage_schema == true && contains(inputs.operation, 'Deploy') }}
        run: |
          endpoint=$(aws rds describe-db-instances \
            --db-instance-identifier "$DB_IDENTIFIER" \
            --query 'DBInstances[0].Endpoint.Address' \
            --output text)

          PGPASSWORD=$DB_PASSWORD psql -h "$endpoint" -U "$DB_USER" -d "$DB_NAME" -f "$DB_SQL_CREATE"
